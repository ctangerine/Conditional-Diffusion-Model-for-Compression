{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22278f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), './')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a101c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_ROOT_DIR = r\"D:\\temp_dataset\\coco\\images\\train2017.1\\train2017\"  # Thư mục gốc chứa COCO\n",
    "TRAIN_IMAGES_SUBDIR = \"\"     # Thư mục con chứa ảnh train2017\n",
    "TRAIN_ANNOTATIONS_FILENAME = \"captions_train2017.json\" # File chú thích cho train2017\n",
    "\n",
    "PATCH_SIZE = (256, 256)  # Kích thước patch mong muốn (height, width)\n",
    "BATCH_SIZE = 32          # Kích thước batch cho DataLoader\n",
    "NUM_WORKERS = 4         # Số luồng để tải dữ liệu\n",
    "\n",
    "# --- Xây dựng đường dẫn đầy đủ ---\n",
    "train_images_path = os.path.join(COCO_ROOT_DIR, TRAIN_IMAGES_SUBDIR)\n",
    "train_annotations_path = os.path.join(r\"D:\\temp_dataset\\coco\\images\\train2017.1\\annotations_trainval2017\\annotations\", TRAIN_ANNOTATIONS_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3cc2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images in D:\\ds_coco_patches\n",
      "Batch size: 1\n",
      "Batch shape: torch.Size([1, 3, 256, 256])\n",
      "Estimated memory usage of the batch on CUDA: 0.75 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------ Example usage ------------------------\n",
    "\n",
    "from data_loader import get_coco_patches_loader\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32  # Adjust based on your GPU memory\n",
    "NUM_WORKERS = 4  # 0 = no multiprocessing\n",
    "MAX_IMAGES = 1  # Limit to first 3000 images\n",
    "\n",
    "train_loader, train_dataset = get_coco_patches_loader(\n",
    "    data_dir=\"D:\\\\ds_coco_patches\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pin_memory=True,\n",
    "    num_workers=0 if torch.cuda.is_available() else 0,\n",
    "    shuffle=True,\n",
    "    cache_size=0,\n",
    "    max_images=MAX_IMAGES\n",
    ")\n",
    "\n",
    "# Move a batch to CUDA and measure its size\n",
    "for images in train_loader:\n",
    "    images = images.cuda()  # Move to CUDA\n",
    "    print(f\"Batch size: {images.size(0)}\")\n",
    "    print(f\"Batch shape: {images.shape}\")  # Should be [B, 3, H, W]\n",
    "    \n",
    "    # Calculate memory usage\n",
    "    batch_memory = images.element_size() * images.nelement() / (1024 ** 2)\n",
    "    print(f\"Estimated memory usage of the batch on CUDA: {batch_memory:.2f} MB\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0699def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([1, 3, 256, 256])\n",
      "Estimated batch size in MB: 0.75\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"Batch shape: {sample_batch.shape}\")\n",
    "print(f\"Estimated batch size in MB: {sample_batch.element_size() * sample_batch.nelement() / 1024**2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ccad66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdc_trainable import CDCTrainable\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CDCTrainable(device=device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b1e0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from compressor.compressor import Compressor\n",
    "# from decompressor.diffusion_manager import DiffusionManager\n",
    "# from decompressor.unet_module import UnetModule\n",
    "\n",
    "\n",
    "# # Initialize the compressor\n",
    "# compressor = Compressor(\n",
    "#     channel_multiplier=[1, 3, 3, 12, 52, 64],\n",
    "#     hyperprior_channel_multiplier=[64,64,64]\n",
    "# )\n",
    "\n",
    "# # Generate a dummy tensor to simulate input data\n",
    "# dummy_tensor = torch.randn(64, 3, 256, 256).cuda()\n",
    "\n",
    "# # Pass the dummy tensor through the compressor\n",
    "# output_dict = compressor(dummy_tensor)\n",
    "\n",
    "# # Extract the shapes of the output tensors\n",
    "# output_shapes = [output.shape[1] for output in output_dict['output']]\n",
    "\n",
    "# # Initialize the UNet module with the extracted channel dimensions\n",
    "# unet_module = UnetModule(\n",
    "#     base_channels=3,\n",
    "#     context_channels=output_shapes\n",
    "# )\n",
    "\n",
    "# del dummy_tensor\n",
    "\n",
    "# model = DiffusionManager(\n",
    "#     encoder=compressor,\n",
    "#     u_net=unet_module,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf296129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 87.09 MB\n"
     ]
    }
   ],
   "source": [
    "def get_model_size_in_mb(model):\n",
    "    total_size = sum(param.element_size() * param.nelement() for param in model.parameters())\n",
    "    total_size += sum(buffer.element_size() * buffer.nelement() for buffer in model.buffers())\n",
    "    return total_size / (1024 ** 2)  # Convert bytes to MB\n",
    "\n",
    "model_size_mb = get_model_size_in_mb(model)\n",
    "print(f\"Model size: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40dc12ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2241059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image(input, save_dir=\"visualizations\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    image = input[0].cpu().detach().numpy()\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    image = Image.fromarray(image)\n",
    "    # Generate a unique filename using timestamp\n",
    "    filename = f\"image_{int(time.time() * 1000)}.png\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    image.save(save_path)\n",
    "    # print(f\"Image saved to {save_path}\")\n",
    "    image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9b51fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "from torch.amp import autocast, GradScaler\n",
    "import tqdm \n",
    "import datetime\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "NUM_WORKERS = 0 if not torch.cuda.is_available() else 0 \n",
    "\n",
    "num_epochs = 20000\n",
    "log_interval = 100\n",
    "save_interval = 50\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=2e-4,  # Typical for diffusion models\n",
    "    weight_decay=1e-4,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Cosine annealing scheduler is common for diffusion models\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=num_epochs,\n",
    "    eta_min=1e-5\n",
    ")\n",
    "\n",
    "save_dir = os.path.join(\"checkpoints\", \n",
    "                        f\"cdc_training_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cd325df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = r\"E:\\DUT Courses\\Academic year 4\\semester 2\\PBL\\PBL7 CDC Compression\\checkpoints\\cdc_training_20250527_170055\"\n",
    "\n",
    "# # Load checkpoint \n",
    "# checkpoint_path = os.path.join(save_dir, f\"checkpoint_epoch_{1550}.pt\")\n",
    "# checkpoint = torch.load(checkpoint_path)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# model.train()  # Set model to training mode\n",
    "# print(f\"Loaded checkpoint from {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3a6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it, loss=1.2036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 completed - Avg Loss: 1.2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20000: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it, loss=1.0688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 completed - Avg Loss: 1.0688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20000: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it, loss=0.9992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 completed - Avg Loss: 0.9992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20000: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it, loss=1.0273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 completed - Avg Loss: 1.0273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20000: 100%|██████████| 1/1 [00:01<00:00,  1.79s/it, loss=1.0018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 completed - Avg Loss: 1.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20000: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it, loss=1.0072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 completed - Avg Loss: 1.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20000: 100%|██████████| 1/1 [00:01<00:00,  1.91s/it, loss=1.0012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 completed - Avg Loss: 1.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20000: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it, loss=1.0376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 completed - Avg Loss: 1.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20000: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it, loss=1.0198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 completed - Avg Loss: 1.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20000: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it, loss=1.0211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 completed - Avg Loss: 1.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20000: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it, loss=1.0038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 completed - Avg Loss: 1.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20000: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it, loss=1.0090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 completed - Avg Loss: 1.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20000: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it, loss=1.0054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 completed - Avg Loss: 1.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20000: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it, loss=0.9941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 completed - Avg Loss: 0.9941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20000: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it, loss=1.0028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 completed - Avg Loss: 1.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20000: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it, loss=0.9974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 completed - Avg Loss: 0.9974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20000: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it, loss=0.9946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 completed - Avg Loss: 0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20000: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it, loss=1.0028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18 completed - Avg Loss: 1.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20000: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it, loss=0.9963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19 completed - Avg Loss: 0.9963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20000: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it, loss=0.9974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20 completed - Avg Loss: 0.9974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/20000: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it, loss=0.9982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21 completed - Avg Loss: 0.9982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/20000:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_dataset.clear_cache()\n",
    "    epoch_losses = []\n",
    "    model.train()\n",
    "\n",
    "    progress_bar = tqdm.tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    image_for_viz = None\n",
    "    predicted_x0 = None\n",
    "    test_image = None\n",
    "\n",
    "    for batch_idx, images in progress_bar:\n",
    "        images = images.to(device)\n",
    "        test_image = images[0].unsqueeze(0)  # For visualization purposes\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(device_type='cuda', enabled=torch.cuda.is_available()):\n",
    "            loss, x0_img, image_noise = model(images)\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            predicted_x0 = x0_img\n",
    "            image_for_viz = image_noise[0].unsqueeze(0)\n",
    "\n",
    "        if torch.isnan(loss).any():\n",
    "            print(f\"NaN in loss at batch {batch_idx}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        if any(torch.isnan(param.grad).any() for param in model.parameters() if param.grad is not None):\n",
    "            print(f\"NaN in gradients at batch {batch_idx}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "        progress_bar.set_postfix({'loss': f\"{epoch_losses[-1]:.4f}\"})\n",
    "\n",
    "        if batch_idx % log_interval == 0 and batch_idx > 0:\n",
    "            avg_recent_loss = sum(epoch_losses[-log_interval:]) / log_interval\n",
    "            print(f\"Batch {batch_idx}/{len(train_loader)} - Avg Loss: {avg_recent_loss:.4f}\")\n",
    "\n",
    "        del loss\n",
    "\n",
    "    avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1} completed - Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % save_interval == 0:\n",
    "        checkpoint_path = os.path.join(save_dir, f\"checkpoint_epoch_{epoch+1}.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "    if (epoch) >= 10000 and predicted_x0 is not None and (epoch + 1) % 500 == 0:\n",
    "        draw_image(predicted_x0)\n",
    "        draw_image(image_for_viz)\n",
    "\n",
    "    if (epoch) >= 10000 and (epoch + 1) % 500 == 0:\n",
    "        model.eval()\n",
    "        # draw_image(test_image, save_dir=\"visualizations_test\")\n",
    "        model.ddim_forward(test_image, denoise_steps=50)\n",
    "        model.train()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0e5190",
   "metadata": {},
   "source": [
    "<h2>OLD MODEL TRAINING PHASE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff6f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)\n",
    "# from torch.utils.data import DataLoader\n",
    "# import tqdm\n",
    "# import datetime\n",
    "# import os\n",
    "# from PIL import Image\n",
    "\n",
    "# import pynvml\n",
    "# pynvml.nvmlInit()\n",
    "# handle = pynvml.nvmlDeviceGetHandleByIndex(torch.cuda.current_device())\n",
    "\n",
    "# def print_gpu_mem(tag=\"\"):\n",
    "#     info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "#     allocated = torch.cuda.memory_allocated() / 1024**2\n",
    "#     reserved = torch.cuda.memory_reserved() / 1024**2\n",
    "#     print(f\"[{tag}] GPU Mem Used (NVML): {info.used / 1024**2:.2f} MB | Allocated (PyTorch): {allocated:.2f} MB | Reserved (PyTorch): {reserved:.2f} MB\")\n",
    "\n",
    "# NUM_WORKERS = 0 if torch.cuda.is_available() else 0\n",
    "\n",
    "# # Training parameters\n",
    "# num_epochs = 20000\n",
    "# log_interval = 50  # Log every 50 batches\n",
    "# save_interval = 100   # Save checkpoint every epoch\n",
    "\n",
    "# # Create optimizer for both compressor and UNet - REMOVED mixed precision components\n",
    "# optimizer = torch.optim.AdamW(\n",
    "#     [\n",
    "#         {'params': model.encoder.parameters()},\n",
    "#         {'params': model.u_net.parameters()}\n",
    "#     ],\n",
    "#     lr=2e-3,  # Typical for diffusion models\n",
    "#     weight_decay=1e-3,\n",
    "#     betas=(0.9, 0.999)\n",
    "# )\n",
    "\n",
    "# # Cosine annealing scheduler is common for diffusion models\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "#     optimizer,\n",
    "#     T_max=num_epochs,\n",
    "#     eta_min=1e-5\n",
    "# )\n",
    "\n",
    "# # Create directory for saving checkpoints\n",
    "# save_dir = os.path.join(\"checkpoints\", \n",
    "#                         f\"cdc_training_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# # Training statistics\n",
    "# train_losses = []\n",
    "# prior_losses = []\n",
    "\n",
    "# # Move models to CUDA\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.to(device)\n",
    "\n",
    "# print(f\"Starting training on {device}\")\n",
    "# print(f\"Training for {num_epochs} epochs with batch size {BATCH_SIZE}\")\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_dataset.clear_cache()  # Clear cache at the start of each epoch\n",
    "#     epoch_losses = []\n",
    "#     epoch_prior_losses = []\n",
    "    \n",
    "#     # Create tqdm progress bar\n",
    "#     progress_bar = tqdm.tqdm(enumerate(train_loader), total=len(train_loader),\n",
    "#                             desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "#     model.train()  # Set model to training mode\n",
    "#     predict_x0_viz = None\n",
    "#     noise = None\n",
    "\n",
    "#     sav_images = None\n",
    "    \n",
    "#     for batch_idx, images in progress_bar:\n",
    "#         images = images.to(device)  # Move images to GPU\n",
    "#         sav_images = images\n",
    "#         # Zero gradients\n",
    "#         optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "#         # Normal forward pass without autocast\n",
    "#         total_loss, prior_loss, estimate_x0, loss_dict, noise_add = model(images)\n",
    "#         # Save a batch for visualization at end of epoch\n",
    "#         if batch_idx == 0:\n",
    "#             predict_x0_viz = estimate_x0    \n",
    "#             noise = noise_add\n",
    "        \n",
    "#         # Check for NaN in losses\n",
    "#         if torch.isnan(total_loss).any() or torch.isnan(prior_loss).any():\n",
    "#             print(f\"NaN detected in losses at batch {batch_idx}. Skipping this batch.\")\n",
    "#             continue\n",
    "\n",
    "#         # combined_loss = total_loss + prior_loss\n",
    "\n",
    "#         # # Check for NaN in loss\n",
    "#         # if torch.isnan(combined_loss).any():\n",
    "#         #     print(f\"NaN detected in combined_loss at batch {batch_idx}. Skipping this batch.\")\n",
    "#         #     continue\n",
    "\n",
    "#         # Standard backward pass\n",
    "#         # combined_loss.backward()\n",
    "#         total_loss.backward()\n",
    "#         # prior_loss.backward()\n",
    "\n",
    "#         # Clip gradients to prevent exploding gradients\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "#         # Check for NaN in gradients\n",
    "#         has_nan_grad = False\n",
    "#         for name, param in model.named_parameters():\n",
    "#             if param.grad is not None and torch.isnan(param.grad).any():\n",
    "#                 print(f\"NaN detected in gradients of parameter {name}. Skipping this batch.\")\n",
    "#                 has_nan_grad = True\n",
    "#                 break\n",
    "        \n",
    "#         if has_nan_grad:\n",
    "#             continue\n",
    "\n",
    "#         # Standard optimizer step\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         loss_item = total_loss.item()\n",
    "#         prior_loss_item = prior_loss.item()\n",
    "#         epoch_losses.append(loss_item)\n",
    "#         epoch_prior_losses.append(prior_loss_item)\n",
    "        \n",
    "#         # Update progress bar\n",
    "#         progress_bar.set_postfix({\n",
    "#             'loss': f\"{epoch_losses[-1]:.4f}\",\n",
    "#             'prior_loss': f\"{epoch_prior_losses[-1]:.4f}\",\n",
    "#             **{key: f\"{value:.4f}\" for key, value in loss_dict.items()}\n",
    "#         })\n",
    "        \n",
    "#         # Log periodically\n",
    "#         if batch_idx % log_interval == 0 and batch_idx > 0:\n",
    "#             print(f\"\\nBatch {batch_idx}/{len(train_loader)}, \"\n",
    "#                 f\"Loss: {sum(epoch_losses[-log_interval:]) / log_interval:.4f}, \"\n",
    "#                 f\"Prior Loss: {sum(epoch_prior_losses[-log_interval:]) / log_interval:.4f}\")\n",
    "\n",
    "#         del total_loss, prior_loss, loss_item, prior_loss_item\n",
    "    \n",
    "#     # Calculate average epoch loss\n",
    "#     avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "#     avg_prior_loss = sum(epoch_prior_losses) / len(epoch_prior_losses)\n",
    "#     train_losses.append(avg_loss)\n",
    "#     prior_losses.append(avg_prior_loss)\n",
    "    \n",
    "#     print(f\"\\nEpoch {epoch+1}/{num_epochs} completed, \"\n",
    "#         f\"Avg Loss: {avg_loss:.4f}, \"\n",
    "#         f\"Avg Prior Loss: {avg_prior_loss:.4f}\")\n",
    "    \n",
    "#     # Save checkpoints\n",
    "#     if (epoch + 1) % save_interval == 0:\n",
    "#         checkpoint_path = os.path.join(save_dir, f\"checkpoint_epoch_{epoch+1}.pt\")\n",
    "#         torch.save({\n",
    "#             'epoch': epoch + 1,\n",
    "#             'encoder_state_dict': model.encoder.state_dict(),\n",
    "#             'unet_state_dict': model.u_net.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': avg_loss,\n",
    "#         }, checkpoint_path)\n",
    "#         print(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "\n",
    "#     if (epoch + 1) >= 3000 and (epoch + 1) % 1 == 0 and predict_x0_viz is not None:\n",
    "#         # show image\n",
    "#         draw_image(predict_x0_viz)\n",
    "#         draw_image(noise)\n",
    "\n",
    "#     if (epoch + 1) >= 4000 and (epoch + 1) % 100 == 0:\n",
    "#         print ((epoch + 1) % 10)\n",
    "#         model.eval()\n",
    "        \n",
    "#         image = sav_images\n",
    "\n",
    "#         start_noise = image\n",
    "#         start_noise = torch.rand_like(start_noise) \n",
    "#         draw_image(start_noise)\n",
    "#         model.evaluate_ddim(image, start_noise, denoise_steps=30)\n",
    "#         model.train()\n",
    "\n",
    "#         torch.cuda.empty_cache()\n",
    "#         gc.collect()\n",
    "\n",
    "\n",
    "#     # Step the learning rate scheduler\n",
    "#     scheduler.step()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587fe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to visualizations\\image_1748328261498.png\n",
      "Step 29/29\n"
     ]
    }
   ],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# def test_ddim():\n",
    "#     model.eval()\n",
    "#     image = sample_batch.cuda()\n",
    "#     start_noise = torch.rand_like(image) \n",
    "#     draw_image(image)\n",
    "#     model.evaluate_ddim(image, start_noise, denoise_steps=30)\n",
    "\n",
    "# test_ddim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab56d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from E:\\DUT Courses\\Academic year 4\\semester 2\\PBL\\PBL7 CDC Compression\\checkpoints\\cdc_training_20250519_013027\\checkpoint_epoch_4000.pt\n"
     ]
    }
   ],
   "source": [
    "# save_dir = r\"E:\\DUT Courses\\Academic year 4\\semester 2\\PBL\\PBL7 CDC Compression\\checkpoints\\cdc_training_20250519_013027\"\n",
    "\n",
    "# # Load checkpoint \n",
    "# checkpoint_path = os.path.join(save_dir, f\"checkpoint_epoch_{4000}.pt\")\n",
    "# checkpoint = torch.load(checkpoint_path)\n",
    "# model.encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "# model.u_net.load_state_dict(checkpoint['unet_state_dict'])\n",
    "# # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# model.train()  # Set model to training mode\n",
    "# print(f\"Loaded checkpoint from {checkpoint_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
